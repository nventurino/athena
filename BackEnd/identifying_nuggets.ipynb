{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "little-jesus",
   "metadata": {},
   "source": [
    "###Read in data and format\n",
    "For my dataset, 0 is a nugget and 1 is noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mature-winning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sklearn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "meaning-traffic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1098\n"
     ]
    }
   ],
   "source": [
    "def read_split_data(fn):\n",
    "    labels = []\n",
    "    utterances = []\n",
    "    with open(fn, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        # This skips the first row of the CSV file.\n",
    "        next(reader)\n",
    "        for row in reader: \n",
    "            labels.append(int(row[0]))\n",
    "            utterances.append(row[1])\n",
    "    print('Number of rows: {}'.format(len(labels)))\n",
    "    data_dict = {\n",
    "        'labels': labels,\n",
    "        'utterances': utterances\n",
    "                }\n",
    "    return data_dict\n",
    "\n",
    "data_dict = read_split_data('utterances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "approved-making",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \"Every robot has a big red button,\" says Dolgov.\n",
      "1 [Page Six] Guess who's putting sluts and hussies ON BLAST?\n",
      "1 A quiet house is nice until you are ordered to stay in it for months.\n",
      "1 A song can make or ruin a personâ€™s day if they let it get to them.\n",
      "1 Abraham's specialty is population and developmental economics.\n"
     ]
    }
   ],
   "source": [
    "#Peek at our dataset\n",
    "for i in range(0,5):\n",
    "    print(data_dict['labels'][i], data_dict['utterances'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rapid-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train, test, and validation sets\n",
    "\n",
    "#requires sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(data_dict['utterances'], data_dict['labels'], test_size=.2)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "choice-account",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9db03c6748643c2b5444fa1a9002f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148daa43b9e2492fb11540c7be2d7c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Alright, weâ€™ve read in our dataset. Now letâ€™s tackle tokenization. Weâ€™ll eventually train a classifier using pre-trained DistilBert, so letâ€™s use the DistilBert tokenizer.\n",
    "\n",
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "powered-latitude",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creat a dataset object\n",
    "\n",
    "#requires torch\n",
    "class utterances_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = utterances_dataset(train_encodings, train_labels)\n",
    "val_dataset = utterances_dataset(val_encodings, val_labels)\n",
    "test_dataset = utterances_dataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "progressive-location",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6068cc11fe22416d98db73831c7cf47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/442 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6b879779984e86ba771026cb1dfa36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myacov\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">./results</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/yacov/huggingface\" target=\"_blank\">https://wandb.ai/yacov/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/yacov/huggingface/runs/3k7ioo8f\" target=\"_blank\">https://wandb.ai/yacov/huggingface/runs/3k7ioo8f</a><br/>\n",
       "                Run data is saved locally in <code>/Users/yacovlewis/Desktop/Workspace/athena/BackEnd/transformers/examples/text-classification/wandb/run-20210312_120346-3k7ioo8f</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yacovlewis/miniconda3/envs/py39_examples/lib/python3.8/site-packages/torch/nn/modules/module.py:760: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/Users/yacovlewis/miniconda3/envs/py39_examples/lib/python3.8/site-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 18:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.659400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.651700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.612900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.548500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.498300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.412300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.273300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.197100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.127100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.160700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.208200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.160400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=132, training_loss=0.3556366400285201, metrics={'train_runtime': 1153.8311, 'train_samples_per_second': 0.114, 'total_flos': 114215873358600, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fine-tuning with Trainer\n",
    "\n",
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "governmental-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./yacov-athena-DistilBertSC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "romance-hello",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./yacov-athena-DistilBertSC/tokenizer_config.json',\n",
       " './yacov-athena-DistilBertSC/special_tokens_map.json',\n",
       " './yacov-athena-DistilBertSC/vocab.txt',\n",
       " './yacov-athena-DistilBertSC/added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./yacov-athena-DistilBertSC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "threaded-polyester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-2.2027936 ,  1.9565878 ],\n",
       "       [-1.996772  ,  1.9063733 ],\n",
       "       [-1.9398148 ,  1.7807553 ],\n",
       "       [-1.9722581 ,  1.7864017 ],\n",
       "       [-1.8825649 ,  1.7188511 ],\n",
       "       [-2.013989  ,  1.7472883 ],\n",
       "       [-2.059013  ,  1.9368087 ],\n",
       "       [-2.119093  ,  1.9426961 ],\n",
       "       [-2.0638952 ,  1.8670772 ],\n",
       "       [-1.9669638 ,  1.8365777 ],\n",
       "       [-2.084086  ,  1.9246064 ],\n",
       "       [-1.8047495 ,  1.659288  ],\n",
       "       [-2.1248512 ,  1.9054465 ],\n",
       "       [-1.9307948 ,  1.7703309 ],\n",
       "       [-2.1210876 ,  1.9037105 ],\n",
       "       [-1.9130121 ,  1.7200853 ],\n",
       "       [-1.9571277 ,  1.7856723 ],\n",
       "       [-2.05442   ,  1.9085035 ],\n",
       "       [-2.0392017 ,  1.8717418 ],\n",
       "       [-1.9413962 ,  1.7846944 ],\n",
       "       [-2.24923   ,  2.0357218 ],\n",
       "       [-2.0544672 ,  1.8760622 ],\n",
       "       [-1.93567   ,  1.7495906 ],\n",
       "       [-2.026557  ,  1.8760918 ],\n",
       "       [-2.072688  ,  1.871838  ],\n",
       "       [-2.0285501 ,  1.8075365 ],\n",
       "       [-2.005712  ,  1.8565831 ],\n",
       "       [-1.8836186 ,  1.7738378 ],\n",
       "       [-0.09321555, -0.0583269 ],\n",
       "       [-2.0794425 ,  1.8361111 ],\n",
       "       [-2.0730946 ,  1.8570262 ],\n",
       "       [-1.9219962 ,  1.6420579 ],\n",
       "       [-2.2255614 ,  2.1123343 ],\n",
       "       [-0.18970272,  0.01296841],\n",
       "       [-2.2236195 ,  2.0834947 ],\n",
       "       [-2.008846  ,  1.8806994 ],\n",
       "       [-0.09444766, -0.05694797],\n",
       "       [-1.9783627 ,  1.851408  ],\n",
       "       [-2.1797523 ,  1.9541662 ],\n",
       "       [-2.0232556 ,  1.8223515 ],\n",
       "       [-2.0735896 ,  1.9002384 ],\n",
       "       [-1.9843544 ,  1.7768182 ],\n",
       "       [-2.0058758 ,  1.8532622 ],\n",
       "       [-2.0361364 ,  1.89967   ],\n",
       "       [-2.0890834 ,  1.8760477 ],\n",
       "       [-2.0414326 ,  1.9239073 ],\n",
       "       [-1.9993899 ,  1.8250988 ],\n",
       "       [-1.9984787 ,  1.8412956 ],\n",
       "       [-1.8488687 ,  1.6527125 ],\n",
       "       [-1.910974  ,  1.7997106 ],\n",
       "       [-1.8941741 ,  1.7560738 ],\n",
       "       [-2.088099  ,  1.9122069 ],\n",
       "       [-0.09559165, -0.0485567 ],\n",
       "       [-2.0987122 ,  1.9519091 ],\n",
       "       [-1.9726593 ,  1.7767044 ],\n",
       "       [-2.0475101 ,  1.8981197 ],\n",
       "       [-2.0853047 ,  2.0081697 ],\n",
       "       [-0.1065608 , -0.04474292],\n",
       "       [-2.1054957 ,  1.8321027 ],\n",
       "       [-2.2036982 ,  2.027749  ],\n",
       "       [-2.1560602 ,  1.9804052 ],\n",
       "       [-2.083728  ,  1.8712239 ],\n",
       "       [-0.09613612, -0.06423111],\n",
       "       [-2.045805  ,  1.8477108 ],\n",
       "       [-1.9970822 ,  1.8320183 ],\n",
       "       [-1.9732925 ,  1.7609978 ],\n",
       "       [-2.093104  ,  1.8510854 ],\n",
       "       [-2.0227733 ,  1.8371667 ],\n",
       "       [-1.9874907 ,  1.8077204 ],\n",
       "       [-1.9628617 ,  1.8354082 ],\n",
       "       [-2.089844  ,  1.8692019 ],\n",
       "       [-2.007972  ,  1.8149126 ],\n",
       "       [-2.0840592 ,  1.8633429 ],\n",
       "       [-2.0626094 ,  1.849695  ],\n",
       "       [-0.10794535, -0.05681355],\n",
       "       [-1.9058447 ,  1.6908926 ],\n",
       "       [-0.09486301, -0.05876141],\n",
       "       [-2.2114725 ,  2.001269  ],\n",
       "       [-2.110511  ,  1.9584281 ],\n",
       "       [-1.9997468 ,  1.8356895 ],\n",
       "       [-1.9474835 ,  1.8107431 ],\n",
       "       [-2.0223622 ,  1.7996686 ],\n",
       "       [-2.0387654 ,  1.8628869 ],\n",
       "       [-1.9799107 ,  1.844723  ],\n",
       "       [-1.9983269 ,  1.8522846 ],\n",
       "       [-2.1327624 ,  1.9292217 ],\n",
       "       [-2.097251  ,  2.0111127 ],\n",
       "       [-1.9356306 ,  1.8717835 ],\n",
       "       [-1.9683412 ,  1.8086874 ],\n",
       "       [-1.9689349 ,  1.7670249 ],\n",
       "       [-2.0052428 ,  1.8444781 ],\n",
       "       [-2.0847025 ,  1.9064283 ],\n",
       "       [-2.1270938 ,  1.9944627 ],\n",
       "       [-2.1291552 ,  1.9465597 ],\n",
       "       [-0.37657124,  0.21350856],\n",
       "       [-1.9983163 ,  1.8300081 ],\n",
       "       [-0.17544822,  0.00722021],\n",
       "       [-0.11346138, -0.0525443 ],\n",
       "       [-2.0045533 ,  1.7941685 ],\n",
       "       [-0.09513696, -0.05120471],\n",
       "       [-1.8466136 ,  1.6710892 ],\n",
       "       [-0.08887807, -0.07131555],\n",
       "       [-1.9536088 ,  1.8592218 ],\n",
       "       [-1.9954499 ,  1.8192981 ],\n",
       "       [-2.095242  ,  1.880507  ],\n",
       "       [-2.1856132 ,  1.9837023 ],\n",
       "       [-2.1549544 ,  1.9572124 ],\n",
       "       [-1.9593146 ,  1.7893648 ],\n",
       "       [-2.0056214 ,  1.8229064 ],\n",
       "       [-2.0974488 ,  1.8826411 ],\n",
       "       [-2.0253482 ,  1.8917682 ],\n",
       "       [-0.18118256,  0.01630117],\n",
       "       [-1.9030592 ,  1.6947393 ],\n",
       "       [-2.077126  ,  1.8765907 ],\n",
       "       [-1.9531741 ,  1.7123786 ],\n",
       "       [-0.0950983 , -0.06839089],\n",
       "       [-1.9762843 ,  1.7653848 ],\n",
       "       [-2.0391874 ,  1.8655474 ],\n",
       "       [-1.9677253 ,  1.7919645 ],\n",
       "       [-2.0427055 ,  1.818136  ],\n",
       "       [-1.9604583 ,  1.8274987 ],\n",
       "       [-0.13767448, -0.03242107],\n",
       "       [-1.9193705 ,  1.7016954 ],\n",
       "       [-2.0624113 ,  1.8590243 ],\n",
       "       [-2.101343  ,  2.0161076 ],\n",
       "       [-2.0712543 ,  1.8476228 ],\n",
       "       [-1.9970164 ,  1.8337349 ],\n",
       "       [-2.0734377 ,  1.8926647 ],\n",
       "       [-2.0510488 ,  1.84304   ],\n",
       "       [-2.0191326 ,  1.8470529 ],\n",
       "       [-2.0574615 ,  1.8908458 ],\n",
       "       [-2.044095  ,  1.8746145 ],\n",
       "       [-1.8242393 ,  1.7083089 ],\n",
       "       [-2.0639765 ,  1.8979452 ],\n",
       "       [-1.9683725 ,  1.7864395 ],\n",
       "       [-2.0380802 ,  1.7854788 ],\n",
       "       [-2.0712245 ,  1.8718808 ],\n",
       "       [-1.9670743 ,  1.8369324 ],\n",
       "       [-2.101204  ,  1.9704022 ],\n",
       "       [-2.0499697 ,  1.8619158 ],\n",
       "       [-2.0093033 ,  1.8833084 ],\n",
       "       [-0.08488286, -0.07131459],\n",
       "       [-1.9142208 ,  1.7648952 ],\n",
       "       [-1.90101   ,  1.6999898 ],\n",
       "       [-2.0522745 ,  1.7489663 ],\n",
       "       [-2.0675492 ,  1.9487712 ],\n",
       "       [-1.9541821 ,  1.8491399 ],\n",
       "       [-2.1357286 ,  1.8276443 ],\n",
       "       [-2.0297873 ,  1.8528318 ],\n",
       "       [-2.0863447 ,  1.87034   ],\n",
       "       [-1.946424  ,  1.778106  ],\n",
       "       [-1.950393  ,  1.8106291 ],\n",
       "       [-2.0387335 ,  1.897429  ],\n",
       "       [-0.1162649 , -0.05648451],\n",
       "       [-1.9903096 ,  1.8032722 ],\n",
       "       [-1.8963    ,  1.7943832 ],\n",
       "       [-2.0656276 ,  1.898235  ],\n",
       "       [-2.131897  ,  1.9515884 ],\n",
       "       [-1.9581708 ,  1.7794641 ],\n",
       "       [-1.917454  ,  1.7696812 ],\n",
       "       [-1.9628332 ,  1.8194182 ],\n",
       "       [-1.9213    ,  1.7589903 ],\n",
       "       [-2.1692512 ,  1.9609941 ],\n",
       "       [-2.1417599 ,  1.9453666 ],\n",
       "       [-2.0720506 ,  1.9240887 ],\n",
       "       [-0.08902846, -0.0639623 ],\n",
       "       [-2.1110432 ,  2.030413  ],\n",
       "       [-1.9287657 ,  1.7942746 ],\n",
       "       [-2.1448035 ,  2.0332189 ],\n",
       "       [-1.9635516 ,  1.8099675 ],\n",
       "       [-1.9994091 ,  1.7952958 ],\n",
       "       [-2.0638995 ,  1.9272754 ],\n",
       "       [-2.1109362 ,  1.9048723 ],\n",
       "       [-1.9863105 ,  1.8035649 ],\n",
       "       [-2.1853597 ,  1.9585558 ],\n",
       "       [-2.0027604 ,  1.8168544 ],\n",
       "       [-2.0039015 ,  1.8691279 ],\n",
       "       [-1.983199  ,  1.7939253 ],\n",
       "       [-2.1089354 ,  1.8675035 ],\n",
       "       [-2.0442073 ,  1.8574612 ],\n",
       "       [-2.031084  ,  1.8626807 ],\n",
       "       [-1.9993874 ,  1.8066285 ],\n",
       "       [-1.9411901 ,  1.8145688 ],\n",
       "       [-2.0661077 ,  1.9037443 ],\n",
       "       [-1.9207844 ,  1.7503811 ],\n",
       "       [-2.2085004 ,  1.9816638 ],\n",
       "       [-1.952009  ,  1.8133006 ],\n",
       "       [-1.8765441 ,  1.6748307 ],\n",
       "       [-1.9691461 ,  1.7579899 ],\n",
       "       [-1.9617752 ,  1.7856793 ],\n",
       "       [-2.0064645 ,  1.8086233 ],\n",
       "       [-1.9059374 ,  1.7058132 ],\n",
       "       [-1.9626677 ,  1.8217574 ],\n",
       "       [-0.11461984, -0.05300487],\n",
       "       [-1.8730376 ,  1.6935911 ],\n",
       "       [-0.08810919, -0.07230249],\n",
       "       [-1.9634414 ,  1.8560729 ],\n",
       "       [-2.0771642 ,  1.8900816 ],\n",
       "       [-1.9826366 ,  1.8074065 ],\n",
       "       [-0.12116376, -0.04304987],\n",
       "       [-2.0972924 ,  1.9117558 ],\n",
       "       [-2.0672402 ,  1.8765048 ],\n",
       "       [-2.0703683 ,  1.8800867 ],\n",
       "       [-1.9142921 ,  1.7724559 ],\n",
       "       [-1.9655471 ,  1.7809802 ],\n",
       "       [-1.9181104 ,  1.7670759 ],\n",
       "       [-1.9719795 ,  1.8251631 ],\n",
       "       [-2.0071707 ,  1.8308563 ],\n",
       "       [-2.123251  ,  1.8660756 ],\n",
       "       [-2.0738652 ,  1.89288   ],\n",
       "       [-2.1377273 ,  1.9969144 ],\n",
       "       [-0.08371869, -0.0672631 ],\n",
       "       [-2.0727377 ,  1.9169077 ],\n",
       "       [-1.9712931 ,  1.818367  ],\n",
       "       [-0.10538001, -0.05099921],\n",
       "       [-2.0319352 ,  1.8268825 ],\n",
       "       [-1.8955619 ,  1.7874576 ],\n",
       "       [-2.0283232 ,  1.9197259 ],\n",
       "       [-2.0078154 ,  1.8183273 ],\n",
       "       [-1.9896812 ,  1.8373159 ]], dtype=float32), label_ids=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1]), metrics={'eval_loss': 0.16373197734355927, 'eval_runtime': 21.0793, 'eval_samples_per_second': 10.437})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "silver-ultimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But CENTCOM and the CIA had decided instead to use the untested Predator. 1\n",
      "The average American woman weighs 166.2 pounds.  And its unclear whether women in the U.S. 1\n",
      "Hurt me 0\n",
      "Schneider is currently a partner in the environment, land, and resources practice at law firm Latham & 1\n",
      "I purchased a baby clown from the Russian terrorist black market. 1\n",
      "Who can help me 0\n",
      "The complicated school homework left the parents trying to help their kids quite confused. 1\n",
      "What can I possible do to survive? 0\n",
      "Amjad is himself only just back in the city, having months ago fled into exile as a result of his association with another Western journalist. 1\n",
      "He decided water-skiing on a frozen lake wasnâ€™t a good idea. 1\n"
     ]
    }
   ],
   "source": [
    "#Review last n results\n",
    "n = 10\n",
    "for i in range(n):\n",
    "    print(test_texts[((len(test_texts)-n -1) + i)], test_labels[((len(test_texts)-n -1) + i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "worldwide-vehicle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counseling Session Transcription\n",
      "Suzie:Â So, yesterday I get home after a long day at work and I check my emailâ€¦.. and there is an email from this guy I hooked up with likeâ€¦.17 years agoâ€¦.something like that.\n",
      "\tâ€¢\tCounselor: Wow.\n",
      "Suzie:Â Thatâ€™s kinda likeâ€¦.. what I was like, I was like Wow! I was like really excited!\n",
      "\tâ€¢\tCounselor: Wow. Okayâ€¦ so you felt excited?\n",
      "Suzie: I did. I felt really exited and I was likeâ€¦. I felt sort of guilty about feeling excited because Iâ€™m likeâ€¦.. hello Iâ€™m married almost 10 Years. But, somebody was obviously paying some kind of attention to me. I have not talked to this guy. I havenâ€™t seen this guyâ€¦. this guy is really like Joe random out of the blueâ€¦. like nothing from him for 17 Years ago.\n",
      "\tâ€¢\tCounselor: Okay.\n",
      "Suzie: And Iâ€™m so flattered. I mean it wasnâ€™t that big of a deal â€¦.the emailâ€¦ whatever but, Iâ€™m so flattered that I almost wish thatâ€¦ that random emailâ€¦.. that act would have been from my husband but it wasnâ€™t. And I got off on the fact that it was from this guy.\n",
      "\tâ€¢\tCounselor: Okay.\n",
      "Suzie: It could have been any guy. It could have been any guy.\n",
      "\tâ€¢\tCounselor: So it sounds like your feeling overwhelmed with all the different roles you are playing.\n",
      "Suzie: Definitely. Uh huhâ€¦..\n",
      "\tâ€¢\tCounselor: And that perhaps youâ€™re feeling, a little like your husband may be a little distant?\n",
      "Suzie: Yeah, like, I kind of feel neglected a little bit. I meanâ€¦. I know that Iâ€™m notâ€¦.itâ€™s crazy cuz , I know Iâ€™m not actually neglected. I think itâ€™s really more my issue.\n",
      "\tâ€¢\tCounselor: Uh huhâ€¦..\n",
      "Suzie: You knowâ€¦. He works more than full-time. He works probably like 50 hours a week.\n",
      "\tâ€¢\tCounselor: Okayâ€¦.\n",
      "Suzie: He takes 3 classes.\n",
      "\tâ€¢\tCounselor: Okayâ€¦.\n",
      "Suzie: Ummâ€¦..he actually does more in the house than I do. I mean heâ€™s, I mean, heâ€™s actually working less so I kind of makes sense in a way. But like I mean he does the laundry, he does the dishes, he irons my clothes in the morning. I mean, by all accounts, most women would think that I have it made. I want to kill him. Ummâ€¦..and I kind of do. Andâ€¦. but just the spark likeâ€¦ I still need the spark. Just because itâ€™s been 10 years doesnâ€™t mean I donâ€™t need the spark.\n",
      "\tâ€¢\tCounselor: Okay, Iâ€™m wondering what that spark is exactly?\n",
      "Suzie: Like what it means to me, you mean?\n",
      "\tâ€¢\tCounselor: What does it mean to you?\n",
      "Suzie: (Sigh) Itâ€™s a really good question I meanâ€¦.(pause) there is you knowâ€¦I think with all relationships there is like a newness that happens. You know when you first start and likeâ€¦. youâ€™re like dating, I meanâ€¦.. I donâ€™t know, I meanâ€¦ itâ€™s really hard to explain. So.. going back to this dating thing cuz thatâ€™s what keeps coming to my head. Like you court the person, I mean I know thatâ€™s an old fashion term and it probably sounds really corny. Like I want to kill myself. But you do things like you make yourself attractive to that person. Youâ€™re romantic. I just want everything to end. Who can help me. Hurt me. Youâ€™reâ€¦.. available.. thereâ€™s like all these things that you are to make yourself attractive to the other person and ummâ€¦. I think that itâ€™s really important. I mean, in marriage to still do that and I know that Iâ€™m having trouble doing that right now because of all my commitments. And my husband and I had a long talk about that before all these changes started and what that was going to look like and if it was manageable, but I still think like I am really emotionally available and Iâ€¦I mean I donâ€™t bring him flowers and stuff cuz heâ€™s never asked for like that being what he needed or whatever. Umâ€¦ he wants things like sex, which I give him because I guess thatâ€™s what heâ€™s driven by. Sometimes I have sex with him and I hate it and I just want everything to go away. Butâ€¦ I needâ€¦ I need thatâ€¦.. whatever thatâ€¦..itâ€™s hard to explain what that spark is butâ€¦. I think you kind of maybe get the picture. Itâ€™s just that newness, that freshness that alive feeling. Likeâ€¦.\n",
      "\tâ€¢\tCounselor: So you need the newness, the freshness, the alive feeling.\n",
      "Suzie: The surprise, like whatâ€™s waiting around the corner. So I guess, and thatâ€™s the whole thing thatâ€¦thatâ€™s why I got off on the email. You know, I mean it really is like out of the clear random blue sky, whatever, this guy that I had a thing for 17 years agoâ€¦. is still thinking about me like that wholeâ€¦that whole concept is kind of â€¦ blows my mind.\n",
      "\tâ€¢\tCounselor: Earlier you were saying something about youâ€™re husband having a lot on his plate as well.\n",
      "Suzie: Uh huhâ€¦.\n",
      "\tâ€¢\tCounselor: And that although he does do all those things outside of the home he also takes care of the home.\n",
      "Suzie: Uh huhâ€¦.\n",
      "\tâ€¢\tCounselor: As well as school and work\n",
      "Suzie: He does a lot. Yeah.\n",
      "\tâ€¢\tCounselor: He does a lot.\n",
      "Suzie: A lot.\n",
      "\tâ€¢\tCounselor: Okay. Iâ€™m wondering how that makes you feel.\n",
      "Suzie: Umâ€¦I mean it obviously makes me feel happy and relieved, proud. Ummâ€¦lucky, you know. But the thing is likeâ€¦I mean I tell him this. Ummâ€¦Iâ€™m really good about that. Iâ€™m very communicative, even when I donâ€™t want to be even when I feel like crap. Likeâ€¦..I thank him and donâ€™t get me wrong, I handle other responsibilities in our household. Like, his mom would never have a birthday card if I didnâ€™t send it, and shop for it, and pick it out, and the whole bit. Likeâ€¦his sisters.. like all of that stuff. None of that stuff would get done. The bills would never be paid. The checkbook would never be balanced. I meanâ€¦. we each have our thing that we are good at and we play to our strengths.\n",
      "\tâ€¢\tCounselor: Okay.\n",
      "Suzie: Umâ€¦.And my husband, I meanâ€¦. heâ€™s a really good guy. I just feel like I need a little more. I do think itâ€™s within me. I think that I feel soâ€¦tired and run down and like drained that Iâ€™m probably looking outside of myself for support and motivation and maybe thatâ€™s the wrong idea. I donâ€™t know.\n",
      "\tâ€¢\tCounselor: Okay. So youâ€™re saying youâ€™re looking for someone on the outside to supply you with all of that energy that you canâ€™t perhaps find within yourself?\n",
      "Suzie: Yeah. I think it is like that. Like, I need a lot of ummâ€¦I do need a lot of validation. Like, I tend to be very hard on myself so I never know if likeâ€¦ Iâ€™m good enough at work, if Iâ€™m good enough at my internship, if Iâ€™m a good enough wife, if Iâ€™m a good enough daughter. I mean, I think, weâ€™ll need a lot more sessions to cover all that. I mean, I think there is a reason for that. I think it comes from my past. Ummâ€¦\n",
      "\tâ€¢\tCounselor: Iâ€™m wondering if your husband knows you need a lot of validation.\n",
      "\n",
      "['Counseling Session Transcription\\nSuzie:\\xa0So, yesterday I get home after a long day at work and I check my emailâ€¦', '', ' and there is an email from this guy I hooked up with likeâ€¦', '17 years agoâ€¦', 'something like that', '\\n\\tâ€¢\\tCounselor: Wow', '\\nSuzie:\\xa0Thatâ€™s kinda likeâ€¦', '', ' what I was like, I was like Wow! I was like really excited!\\n\\tâ€¢\\tCounselor: Wow', ' Okayâ€¦ so you felt excited?\\nSuzie: I did', ' I felt really exited and I was likeâ€¦', ' I felt sort of guilty about feeling excited because Iâ€™m likeâ€¦', '', ' hello Iâ€™m married almost 10 Years', ' But, somebody was obviously paying some kind of attention to me', ' I have not talked to this guy', ' I havenâ€™t seen this guyâ€¦', ' this guy is really like Joe random out of the blueâ€¦', ' like nothing from him for 17 Years ago', '\\n\\tâ€¢\\tCounselor: Okay', '\\nSuzie: And Iâ€™m so flattered', ' I mean it wasnâ€™t that big of a deal â€¦', 'the emailâ€¦ whatever but, Iâ€™m so flattered that I almost wish thatâ€¦ that random emailâ€¦', '', ' that act would have been from my husband but it wasnâ€™t', ' And I got off on the fact that it was from this guy', '\\n\\tâ€¢\\tCounselor: Okay', '\\nSuzie: It could have been any guy', ' It could have been any guy', '\\n\\tâ€¢\\tCounselor: So it sounds like your feeling overwhelmed with all the different roles you are playing', '\\nSuzie: Definitely', ' Uh huhâ€¦', '', '\\n\\tâ€¢\\tCounselor: And that perhaps youâ€™re feeling, a little like your husband may be a little distant?\\nSuzie: Yeah, like, I kind of feel neglected a little bit', ' I meanâ€¦', ' I know that Iâ€™m notâ€¦', 'itâ€™s crazy cuz , I know Iâ€™m not actually neglected', ' I think itâ€™s really more my issue', '\\n\\tâ€¢\\tCounselor: Uh huhâ€¦', '', '\\nSuzie: You knowâ€¦', ' He works more than full-time', ' He works probably like 50 hours a week', '\\n\\tâ€¢\\tCounselor: Okayâ€¦', '\\nSuzie: He takes 3 classes', '\\n\\tâ€¢\\tCounselor: Okayâ€¦', '\\nSuzie: Ummâ€¦', '', 'he actually does more in the house than I do', ' I mean heâ€™s, I mean, heâ€™s actually working less so I kind of makes sense in a way', ' But like I mean he does the laundry, he does the dishes, he irons my clothes in the morning', ' I mean, by all accounts, most women would think that I have it made', ' I want to kill him', ' Ummâ€¦', '', 'and I kind of do', ' Andâ€¦', ' but just the spark likeâ€¦ I still need the spark', ' Just because itâ€™s been 10 years doesnâ€™t mean I donâ€™t need the spark', '\\n\\tâ€¢\\tCounselor: Okay, Iâ€™m wondering what that spark is exactly?\\nSuzie: Like what it means to me, you mean?\\n\\tâ€¢\\tCounselor: What does it mean to you?\\nSuzie: (Sigh) Itâ€™s a really good question I meanâ€¦', '(pause) there is you knowâ€¦I think with all relationships there is like a newness that happens', ' You know when you first start and likeâ€¦', ' youâ€™re like dating, I meanâ€¦', '', ' I donâ€™t know, I meanâ€¦ itâ€™s really hard to explain', ' So', '', ' going back to this dating thing cuz thatâ€™s what keeps coming to my head', ' Like you court the person, I mean I know thatâ€™s an old fashion term and it probably sounds really corny', ' Like I want to kill myself', ' But you do things like you make yourself attractive to that person', ' Youâ€™re romantic', ' I just want everything to end', ' Who can help me', ' Hurt me', ' Youâ€™reâ€¦', '', ' available', '', ' thereâ€™s like all these things that you are to make yourself attractive to the other person and ummâ€¦', ' I think that itâ€™s really important', ' I mean, in marriage to still do that and I know that Iâ€™m having trouble doing that right now because of all my commitments', ' And my husband and I had a long talk about that before all these changes started and what that was going to look like and if it was manageable, but I still think like I am really emotionally available and Iâ€¦I mean I donâ€™t bring him flowers and stuff cuz heâ€™s never asked for like that being what he needed or whatever', ' Umâ€¦ he wants things like sex, which I give him because I guess thatâ€™s what heâ€™s driven by', ' Sometimes I have sex with him and I hate it and I just want everything to go away', ' Butâ€¦ I needâ€¦ I need thatâ€¦', '', ' whatever thatâ€¦', '', 'itâ€™s hard to explain what that spark is butâ€¦', ' I think you kind of maybe get the picture', ' Itâ€™s just that newness, that freshness that alive feeling', ' Likeâ€¦', '\\n\\tâ€¢\\tCounselor: So you need the newness, the freshness, the alive feeling', '\\nSuzie: The surprise, like whatâ€™s waiting around the corner', ' So I guess, and thatâ€™s the whole thing thatâ€¦thatâ€™s why I got off on the email', ' You know, I mean it really is like out of the clear random blue sky, whatever, this guy that I had a thing for 17 years agoâ€¦', ' is still thinking about me like that wholeâ€¦that whole concept is kind of â€¦ blows my mind', '\\n\\tâ€¢\\tCounselor: Earlier you were saying something about youâ€™re husband having a lot on his plate as well', '\\nSuzie: Uh huhâ€¦', '\\n\\tâ€¢\\tCounselor: And that although he does do all those things outside of the home he also takes care of the home', '\\nSuzie: Uh huhâ€¦', '\\n\\tâ€¢\\tCounselor: As well as school and work\\nSuzie: He does a lot', ' Yeah', '\\n\\tâ€¢\\tCounselor: He does a lot', '\\nSuzie: A lot', '\\n\\tâ€¢\\tCounselor: Okay', ' Iâ€™m wondering how that makes you feel', '\\nSuzie: Umâ€¦I mean it obviously makes me feel happy and relieved, proud', ' Ummâ€¦lucky, you know', ' But the thing is likeâ€¦I mean I tell him this', ' Ummâ€¦Iâ€™m really good about that', ' Iâ€™m very communicative, even when I donâ€™t want to be even when I feel like crap', ' Likeâ€¦', '', 'I thank him and donâ€™t get me wrong, I handle other responsibilities in our household', ' Like, his mom would never have a birthday card if I didnâ€™t send it, and shop for it, and pick it out, and the whole bit', ' Likeâ€¦his sisters', '', ' like all of that stuff', ' None of that stuff would get done', ' The bills would never be paid', ' The checkbook would never be balanced', ' I meanâ€¦', ' we each have our thing that we are good at and we play to our strengths', '\\n\\tâ€¢\\tCounselor: Okay', '\\nSuzie: Umâ€¦', 'And my husband, I meanâ€¦', ' heâ€™s a really good guy', ' I just feel like I need a little more', ' I do think itâ€™s within me', ' I think that I feel soâ€¦tired and run down and like drained that Iâ€™m probably looking outside of myself for support and motivation and maybe thatâ€™s the wrong idea', ' I donâ€™t know', '\\n\\tâ€¢\\tCounselor: Okay', ' So youâ€™re saying youâ€™re looking for someone on the outside to supply you with all of that energy that you canâ€™t perhaps find within yourself?\\nSuzie: Yeah', ' I think it is like that', ' Like, I need a lot of ummâ€¦I do need a lot of validation', ' Like, I tend to be very hard on myself so I never know if likeâ€¦ Iâ€™m good enough at work, if Iâ€™m good enough at my internship, if Iâ€™m a good enough wife, if Iâ€™m a good enough daughter', ' I mean, I think, weâ€™ll need a lot more sessions to cover all that', ' I mean, I think there is a reason for that', ' I think it comes from my past', ' Ummâ€¦\\n\\tâ€¢\\tCounselor: Iâ€™m wondering if your husband knows you need a lot of validation', '\\n']\n"
     ]
    }
   ],
   "source": [
    "f1 = open('therapy_transcript.txt', 'r')\n",
    "therapy_utterances = f1.read().splitlines()\n",
    "\n",
    "f1 = open('therapy_transcript.txt', 'r')\n",
    "therapy_utterances = f1.read()\n",
    "print(therapy_utterances)\n",
    "therapy_utterances = therapy_utterances.split('.')\n",
    "print(therapy_utterances)\n",
    "live_encodings = tokenizer(therapy_utterances, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-valentine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "inputs = tokenizer(therapy_utterances[0], return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)\n",
    "outputs = model(**inputs, labels=labels)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "functioning-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits:  tensor([[  2.3559,   9.1067, -11.3278],\n",
      "        [ -6.0727, -19.6020,  -1.2912]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.1340e-01, 9.9989e-01, 1.2034e-05],\n",
       "        [2.2996e-03, 3.0687e-09, 2.1566e-01]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getSoftmaxScores(inputs, dimen):\n",
    "\t''' Get the softmax scores '''\n",
    "\tprint('---Softmax---')\n",
    "\tprint('---Dim = ' + str(dimen) + '---')\n",
    "\tsoftmaxFunc = torch.nn.Softmax(dim = dimen)\n",
    "\tsoftmaxScores = softmaxFunc(inputs)\n",
    "\tprint('Softmax Scores: \\n', softmaxScores)\n",
    "\tsums_0 = torch.sum(softmaxScores, dim=0)\n",
    "\tsums_1 = torch.sum(softmaxScores, dim=1)\n",
    "\tprint('Sum over dimension 0: \\n', sums_0)\n",
    "\tprint('Sum over dimension 1: \\n', sums_1)\n",
    "\n",
    "def getSigmoidScores(inputs):\n",
    "\t''' Get the sigmoid scores: they are element-wise '''\n",
    "\t#print('---Sigmoid---')\n",
    "\tsigmoidScores = torch.sigmoid(inputs)\n",
    "\t#print('Sigmoid Scores: \\n', sigmoidScores)\n",
    "\treturn sigmoidScores\n",
    "\n",
    "logits = torch.randn(2, 3)*10 - 5\n",
    "print('Logits: ', logits)\n",
    "getSigmoidScores(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "early-sydney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " I want to kill him \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Like I want to kill myself \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Youâ€™re romantic \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " I just want everything to end \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Who can help me \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Hurt me \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Likeâ€¦ \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Likeâ€¦ \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Likeâ€¦his sisters \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " I do think itâ€™s within me \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " I donâ€™t know \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " I think it comes from my past \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " Here is a high risk sentence!!! \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(therapy_utterances)):\n",
    "    inputs = tokenizer(therapy_utterances[i], return_tensors=\"pt\")\n",
    "    labels = torch.tensor([1]).unsqueeze(0)\n",
    "    outputs = model(**inputs, labels=labels)\n",
    "    probablities = getSigmoidScores(outputs.logits)\n",
    "    #print(therapy_utterances[i], probablities)\n",
    "    if probablities[0,0] > .47:\n",
    "        print(therapy_utterances[i],'\\n\\n\\n\\n Here is a high risk sentence!!! \\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-iceland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_examples",
   "language": "python",
   "name": "py39_examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
